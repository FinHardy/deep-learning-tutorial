{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fc79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e892ac",
   "metadata": {},
   "source": [
    "# Setup of an AI model \n",
    "\n",
    "1. Dataloader \n",
    "Code to load in your data in a format that your model expects it\n",
    "\n",
    "2. Model Architecture \n",
    "Workhorse code that is actually doing the computation and \n",
    "\n",
    "3. Training Loop \n",
    "Code to train your model and \n",
    "\n",
    "4. Eval/Inference Loop \n",
    "Need to assess the effectiveness of your model before you use it in the real world!\n",
    "\n",
    "Inference loop to see the results of the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52979697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 13.0MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 392kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.62MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 31.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import os\n",
    "\n",
    "# Download MNIST dataset\n",
    "data_dir = os.path.join(os.getcwd(), 'mnist_data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "train_dataset = datasets.MNIST(root=data_dir, train=True, download=True)\n",
    "test_dataset = datasets.MNIST(root=data_dir, train=False, download=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54900910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Visualize MNIST sample\n",
    "from torchvision import datasets\n",
    "\n",
    "mnist_data = datasets.MNIST(root='mnist_data', train=True, download=True)\n",
    "sample_img, sample_label = mnist_data[0]\n",
    "\n",
    "plt.imshow(sample_img, cmap='gray')\n",
    "plt.title(f'Label: {sample_label}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {np.array(sample_img).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d315b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader for MNIST\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "def create_mnist_dataloader(data_dir, train=True, batch_size=64, shuffle=True):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.MNIST(root=data_dir, train=train, transform=transform, download=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc568835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Neural Network Model for MNIST\n",
    "\n",
    "class SimpleCNNModel(nn.Module): \n",
    "    def __init__(self, input_channels, num_classes): \n",
    "        super(SimpleCNNModel, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) \n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # After 2 pooling: 28x28 -> 14x14 -> 7x7\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        \n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3fb5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop \n",
    "# IMPORTANT set device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader: # unpack batched data from dataloader\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad() # zero the parameter gradients\n",
    "\n",
    "            outputs = model(inputs) # forward pass of data through model\n",
    "\n",
    "            loss = criterion(outputs, labels) # calculate difference between model output and expected ouptut \n",
    "\n",
    "            loss.backward() # propogate the loss backward through the model\n",
    "\n",
    "            optimizer.step() # update model parameters based on gradients\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0) # update running loss\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435106eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.1749\n",
      "Epoch 2/5, Loss: 0.0597\n",
      "Epoch 3/5, Loss: 0.0431\n",
      "Epoch 4/5, Loss: 0.0334\n",
      "Epoch 5/5, Loss: 0.0266\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'mnist_data')\n",
    "\n",
    "model = SimpleCNNModel(input_channels=1, num_classes=10)  # MNIST is grayscale (1 channel), 10 digits\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataloader = create_mnist_dataloader(data_dir, train=True, batch_size=64, shuffle=True)\n",
    "\n",
    "train_model(model, train_dataloader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16399f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval/inference loop \n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval() # put the model in evaluation mode so that it is not calculating gradients\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aae565f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.30%\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = create_mnist_dataloader(data_dir, train=False, batch_size=64, shuffle=False)\n",
    "evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a469d010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 6, True: 6\n"
     ]
    }
   ],
   "source": [
    "# Test on a random MNIST image\n",
    "test_data = datasets.MNIST(root='mnist_data', train=False, download=True)\n",
    "idx = np.random.randint(len(test_data))\n",
    "test_img, true_label = test_data[idx]\n",
    "\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.title(f'True Label: {true_label}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "model.eval()\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "img_tensor = transform(test_img).unsqueeze(0).to(device)\n",
    "output = model(img_tensor)\n",
    "_, predicted_class = torch.max(output, 1)\n",
    "\n",
    "print(f'Predicted: {predicted_class.item()}, True: {true_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c5643d",
   "metadata": {},
   "source": [
    "Useful papers: https://github.com/awesomelistsio/awesome-ai-research-papers\n",
    "\n",
    "Personal Favourites: \n",
    "Reinforcement learning on atari games: https://www.nature.com/articles/nature14236\n",
    "Accurate protein folding: https://www.nature.com/articles/s41586-021-03819-2\n",
    "Grokking: http://arxiv.org/abs/2201.02177\n",
    "Image generation with latent diffusion: http://arxiv.org/abs/2112.10752\n",
    "Intro to graphs: https://distill.pub/2021/gnn-intro/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
